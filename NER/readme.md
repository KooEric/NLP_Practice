# Making Perfume Name Entities Recongnition Spacy Model
### Rule-based Model

1. Crawling Perfume Reviews and Details
2. Make Perfume Note, Accord Entities


# 1.  ë¬¸ì œ ì •ì˜

<aside>
ğŸ’¡ ë°ì´í„° ë°”ìš°ì²˜ ì´í›„ **í–¥ìˆ˜ ì¶”ì²œ ì„œë¹„ìŠ¤ë¥¼ í•˜ê¸° ìœ„í•´** **í–¥ê³¼ ë…¸íŠ¸, ë…¸íŠ¸ ì¡°í•©ë“±ì˜ ê°œì²´ëª… ì¸ì‹ì´ í•„ìš”í•˜ë¯€ë¡œ,** ê°œì²´ëª… ì¸ì‹ê¸°ë¥¼ ê°œë°œí•˜ì˜€ìŒ.

</aside>

## 1.1 Spacy Rule-based Model ì‚¬ìš© ì´ìœ 

ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ ë°ì´í„°ì…‹ì„ ë§Œë“œëŠ” ê²ƒì´ ì¤‘ìš”í•œë°, NER datasetì˜ ê²½ìš° ê³µìœ ëœ datasetì´ ë§ì§€ ì•Šìœ¼ë©°, êµ¬ì¶•í•˜ê¸° ê¹Œë‹¤ë¡­ë‹¤. 

ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì—¬ í•´ë‹¹ ëª¨ë¸ì— í•™ìŠµê¹Œì§€ì˜ ì‹œê°„ì´ ì´‰ë°•í•˜ì—¬ í•´ë‹¹ ì¸ì‹ê¸°ëŠ” í”íˆ ì‚¬ìš©í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì¸ BERT-NER ë˜ëŠ” LSTM+CRFì´ ì•„ë‹ˆë¼, ì˜ì–´ ì „ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ Spacyë¥¼ ì´ìš©í•˜ì—¬ Rule-based ëª¨ë¸ì„ ì œì‘í•˜ì˜€ìŒ.

# 2. ìˆ˜ì§‘ ë²”ìœ„ ë° ë°ì´í„° í™•ì¸

## 2.1 ìˆ˜ì§‘ë²”ìœ„

ìˆ˜ì§‘ ë°ì´í„°ëŠ” [https://www.fragrantica.com/](https://www.fragrantica.com/) ì‚¬ì´íŠ¸ì˜ í–¥ìˆ˜ ì •ë³´ì„.

ìˆ˜ì§‘ëœ ë°ì´í„°ëŠ” ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ perfumeDetail_result.csv, perfumeReview_result.csv ìƒì„¸ì •ë³´ì™€ ë¦¬ë·°ë°ì´í„° ë‘ ê°œì˜ íŒŒì¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.

## 2.2 ë°ì´í„° í™•ì¸

- Detail íŒŒì¼(63,486ê°œ)

í•´ë‹¹ ëª¨ë¸ì—ì„œëŠ” accordsì™€ notes ì •ë³´ë§Œì„ ì‚¬ìš©í•¨.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/02e377f9-f3d6-44d9-ba96-8915ddbf0e94/Untitled.png)

- Review íŒŒì¼(398,583ê°œ)

í•´ë‹¹ ëª¨ë¸ì—ì„œëŠ” review ë°ì´í„°ë§Œ ì‚¬ìš©í•¨.

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8b2f18b4-04c8-4780-9c3a-6401e0c66874/Untitled.png)

# 3. ì½”ë“œ ë‚´ìš©

<aside>
ğŸ–‹ï¸ Spacy ëª¨ë¸ì˜ ê²½ìš°, 3.0 ë²„ì „ì´ ìƒˆë¡œ ì—…ë°ì´íŠ¸ ë˜ì–´ ê¸°ì¡´ 2.1 ë²„ì „ê³¼ ë‹¤ë¥¸ ë¶€ë¶„ì´ ìˆì–´, 3.0ë²„ì „ì— ë§ì¶° ì œì‘í•˜ì˜€ìŒ.

</aside>

## 3.1 Import Part

```python
import pandas as pd # csv íŒŒì¼
from nltk.corpus import stopwords # ì˜ì–´ ì „ì²˜ë¦¬
from nltk.tokenize import RegexpTokenizer # ì˜ì–´ ì „ì²˜ë¦¬
from __future__ import unicode_literals, print_function
import random
from pathlib import Path
import spacy # ê°œì²´ëª… í•™ìŠµ
from tqdm import tqdm # í•™ìŠµê³¼ì • í™•ì¸
from spacy.util import minibatch # ê°œì²´ëª… í•™ìŠµ
from spacy.training.example import Example # ê°œì²´ëª… í•™ìŠµ
```

## 3.2 Detail ë°ì´í„° íŒ¨í„´í™” ì‘ì—…

- Detail ì •ë³´ íŒë‹¤ìŠ¤ í”„ë ˆì„í™”

```python
nlp = spacy.load('en_core_web_sm')
df = pd.read_csv('/saltlux_BERT/perfumeReview_crawling/perfumeDetail_result.csv', \n
									encoding='utf-8').fillna("") # fillna("")ë¥¼ í†µí•´ ê²°ì¸¡ê°’ì˜ ê³µë°±ì„ ë©”ì›Œì¤Œ
df.head()
```

spacy.load(â€™en_core_web_smâ€™)ì˜ ì—ëŸ¬ê°€ ë°œìƒí•  ê²½ìš°, spacy.download()ë¥¼ í†µí•´ ë‹¤ìš´ë¡œë“œí•˜ì—¬ì•¼ í•¨.

```python
df['notes']=df['notes'].dropna() # notes ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì‚­ì œ
df['accords']=df['accords'].dropna() # accords ì»¬ëŸ¼ ê²°ì¸¡ê°’ ì‚­ì œ
```

- note, accord ì •ë³´ ê°€ì ¸ì˜¤ê¸°

Detail íŒŒì¼ ë‚´ notes, accordsëŠ” â€˜|â€™ì™€ ê°™ì€ êµ¬ë¶„ìë¡œ ìˆ˜ì§‘ë˜ì–´ ìˆìŒ.

```python

# ë¹ˆ ë¦¬ìŠ¤íŠ¸ì— ë­‰ì³ìˆëŠ” ê°’ë“¤ì„ í•˜ë‚˜ì”© ë§Œë“¤ì–´ì¤€ë‹¤.
## accords
accords = df['accords'].tolist()
accord = []

for i in range(len(accords)):
    tmp = accords[i].split('|')
    for j in tmp:
        if j not in accord:
            accord.append(j)
## notes
notes = df['notes'].tolist()
note = [] 

for i in range(len(notes)):
    tmp = notes[i].split('|')
    for j in tmp:
        if j not in note:
            note.append(j)
```

- ë¹ˆ ê°’ë“¤ë¡œ ì¸í•œ ì‚¬ì†Œí•œ ì—ëŸ¬ë“¤ ì‚¬ì „ ì œê±°

```python
note.remove('')
accord.remove('')
```

- í•´ë‹¹ ë°ì´í„°ë“¤ì„ íŒ¨í„´í™” í•˜ê¸° ìœ„í•œ ì‘ì—…

```python
accord = set(accord)
note = set(note)
```

```python
accord_patterns = []
for item in note:
    accord_pattern = {'label': 'accord', 'pattern': item}
    accord_patterns.append(accord_pattern)
accord_patterns

note_patterns =[]
for item in note:
    note_pattern = {'label': 'note', 'pattern': item}
    note_patterns.append(note_pattern)
note_patterns
```

- íŒ¨í„´í™”ëœ ê°’ë“¤ì„ í•˜ë‚˜ì˜ í†µí•© íŒ¨í„´ìœ¼ë¡œ ë§Œë“¤ê¸°

```python
total_patterns = []
total_patterns.extend(note_patterns)
total_patterns.extend(accord_patterns) # ë¦¬ìŠ¤íŠ¸ í™•ì¥

total_patterns[1000] # ë°ì´í„° í™•ì¸
```

ê²°ê³¼ê°’ : {'label': 'note', 'pattern': 'Pitanga'}

## 3.3 ë¦¬ë·° ë°ì´í„° ì „ì²˜ë¦¬

```python
df2 = pd.read_csv('/saltlux_BERT/perfumeReview_crawling/perfumeReview_result.csv', \n
									encoding='utf-8').fillna("") # ë¦¬ë·°ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
```

```python
# í•¨ìˆ˜ ì„ ì–¸
def make_lower_case(text): # ì†Œë¬¸ìë¡œ ë§Œë“¤ì–´ì¤€ë‹¤.
    return text.lower()

def remove_stop_words(text): # Stop_word(ex. the, a ë“±ì„ ì‚­ì œ)
    text = text.split()
    stops = set(stopwords.words("english"))
    text = [w for w in text if not w in stops]
    text = " ".join(text)
    return text
```

- ì „ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©

```python
# df2['review'] = df2.review.apply(func=make_lower_case)
df2['review'] = df2.review.apply(func=remove_stop_words)

rr = df2['review'].tolist() # ë¦¬ë·°ë°ì´í„° ë¦¬ìŠ¤íŠ¸í™”
```

í•´ë‹¹ ë¶€ë¶„ì—ì„  ê³ ìœ ì˜ í–¥ì„ ì ìš©í•˜ê¸° ìœ„í•´ ì†Œë¬¸ì í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì§€ ì•Šì•˜ë‹¤.

- í•™ìŠµ ë°ì´í„° ìˆ˜ëŸ‰ ì„¤ì •

```python
total_R = ','.join(rr[:2000]) # ë©”ëª¨ë¦¬ ì´ˆê³¼ë¡œ ì¸í•´ 2000ê±´ì˜ ë°ì´í„°ë¡œ í•™ìŠµì„ ì§„í–‰
total_R
```

## 3.4 Rule-based ëª¨ë¸ í•™ìŠµ

- í•™ìŠµ ë°ì´í„° ë§Œë“¤ê¸°

```python
# í•™ìŠµ
nlp = spacy.load("en_core_web_sm")
text = total_R
corpus = []

doc = nlp(text)
for sent in doc.sents:
    corpus.append(sent.text)

nlp = spacy.blank("en")
ruler = nlp.add_pipe("entity_ruler")
patterns = total_patterns
# nlp = spacy.blank("en")
ruler.add_patterns(patterns)

TRAIN_DATA = []
for sentence in corpus:
    doc = nlp(sentence)
    entities = []

    for ent in doc.ents:
        if len(ent) > 0:
            entities.append((ent.start_char, ent.end_char, ent.label_))
        # entities.append((ent.text, ent.label_))
        TRAIN_DATA.append((sentence, {"entities": entities}))

print (TRAIN_DATA)
```

```python
# í•™ìŠµ
model = None
output_dir=Path("./content")
n_iter=50

#load the model
if model is not None:
    nlp = spacy.load(model)
    print("Loaded model '%s'" % model)
else:
    nlp = spacy.blank('en')
    print("Created blank 'en' model")

#set up the pipeline

if 'ner' not in nlp.pipe_names:
    ner = nlp.add_pipe('ner', last=True)
else:
    ner = nlp.get_pipe('ner')
```

- ëª¨ë¸ í•™ìŠµ

```python
# í•™ìŠµ ì‹œì‘
from spacy.training.example import Example

for _, annotations in TRAIN_DATA:
    for ent in annotations.get('entities'):
        ner.add_label(ent[2])

other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']

loss_history = []
train_examples = []
for text, annotations in TRAIN_DATA:
    train_examples.append(Example.from_dict(nlp.make_doc(text), annotations))
with nlp.disable_pipes(*other_pipes):  # only train NER
    optimizer = nlp.begin_training()
    for itn in range(n_iter):
        random.shuffle(TRAIN_DATA)
        losses = {}
        batches = minibatch(train_examples, size=spacy.util.compounding(4.0, 32.0, 1.001))
        batches_list = [(idx, batch) for idx, batch in enumerate(batches)]
        for idx, batch in tqdm(batches_list):
            nlp.update(
                batch,
                drop=0.5,
                sgd=optimizer,
                losses=losses)
        loss_history.append(losses)
        print(losses)
```

- í•™ìŠµ ê²°ê³¼ í™•ì¸

```python
for text, _ in TRAIN_DATA:
    doc = nlp(text)
    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])
```

- í•™ìŠµ ëª¨ë¸ ì €ì¥

```python
# í•™ìŠµ
if output_dir is not None:
    output_dir = Path(output_dir)
    if not output_dir.exists():
        output_dir.mkdir()
    nlp.to_disk(output_dir)
    print("Saved model to", output_dir)
```

- ëª¨ë¸ ì „ì²´ ë¦¬ë·°ë°ì´í„° ì ìš©

```python
# ì €ì¥ëœ ê°œì²´ëª… ì¸ì‹ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°, í™œìš©
print("Loading from", '/content')
nlp2 = spacy.load('/Users/yhkoo/PycharmProjects/pythonProject/deep/saltlux_BERT/content')
DATA = df2['review']
dataframe = []
for text in DATA:
    if len(ent) > 0:
        doc = nlp2(text)
        print('Entities', [(ent.text, ent.label_) for ent in doc.ents])
    dataframe.append({'Entities': [(ent.text, ent.label_) for ent in doc.ents]})
```

## 3.5 ìµœì¢… ê²°ê³¼ í†µí•©

```python
result =pd.DataFrame(dataframe, columns=['Entities']) # Entities ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë°ì´í„° í”„ë ˆì„í™”

final = pd.concat([df2, result], axis=1) # ë¦¬ë·° ë°ì´í„°ì™€ ê²°í•¨
final.to_csv('./final_merge_entitiy.csv') # csvíŒŒì¼ ë§Œë“¤ê¸°
```
